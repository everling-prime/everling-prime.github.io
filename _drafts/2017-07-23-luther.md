---
published: false
---
# DARK WEB DRUG MARKET PREDICTION

## Project Luther

**Objective**: Using machine learning, train linear regression and decision tree models to predict a continuous numeric variable from a web-scraped data set.

**Subject**: Price distributions on the hidden markets of the [dark web](https://en.wikipedia.org/wiki/Dark_web).

**Description**: It is remarkably easy for anyone with internet access to visit dark web marketplaces and view product listings. I herein use Python code to simulate the behavior of a human browsing these markets, selectively collect and save information from each market page this browsing agent views, and finally use the collected data in aggregate to construct a predictive pricing model. 

---
    
  
## Context
Dark web marketplaces (cryptomarkets) are internet markets that facilitate anonymous buying and selling. Anonymity means that many of these markets trade illegal goods, as it is inherently difficult for law enforcement to intercept information or identify users. 

While [black markets](https://en.wikipedia.org/wiki/Black_market) have existed as long as regulated commerce itself, dark web markets were born somewhat recently when 4 technologies combined:

* Anonymous internet browsing (e.g. Tor and the Onion network)
* Virtual currencies (e.g. Bitcoin)
* Escrow (conditional money transfer)
* Vendor feedback systems (Amazon.com-like ratings of sellers)

Total cash flow through dark web markets is hard to estimate, but indicators show it as substantial and rising. The biggest vendors can earn millions of dollars per year.

The market studied for this project is called [Dream Market](https://www.deepdotweb.com/marketplace-directory/listing/dream-market/).

## Extra Fun Context

After bragging a little too loudly in a seedy Mexican cantina about your magic data science powers of prediction, you have been kidnapped by a forward-thinking drug cartel. They have developed a plan to sell their stock of cocaine on the internet. They demand that you help them develop a pricing model that will give them the most profit. If you do not, your life will be forfeit!

You, knowing nothing about cocaine or drug markets, immediately panic. Your life flashes before your eyes as the reality of your tragic end sets in. Eventually, the panic subsides and you remember that if you can just browse the market, you might be able to pick up on some patterns and save your life.

## The Market

Browsing Dream Market reveals a few things:

* There is an active market for cocaine already, with thousands of product listings
* Prices aren't consistent. Some vendors sell their cocaine for less than others.
* The main factor that determines price seems to be quantity, but there are some other less obvious factors too.

There are some quantities associated with product listing:
* how many grams the offer is for
* how much the offer costs
* what percentage purity the cocaine is

There are patterns in the data to be sure, but there's too much to sift through for one person. 


## Tools

**BeautifulSoup** automates the process of capturing information from HTML tags based on patterns I specify. For example, to collect the title strings of each cocaine listing, I use BeautifulSoup to search all the HTML of each search results page for `<div>` tags that have `class=productTitle`, and save the text contents of any such tag found.

**Selenium** automates browsing behavior. In this case, its primary function is simply to go to the market listings and periodically click to the next page of search results, so that BeautifulSoup can then scrape the data. I set a `sleep` timeout in the code so that the function would make http requests at a reasonably slow rate.

**Pandas** to tabularize the data in Python and stage it for analysis.

[**Scikit Learn**](http://scikit-learn.org/stable/) for regression and model selection.


## Data Collection

I build a dictionary of page objects, which includes:
* product listing
 * listing title
 * listing price
 * vendor name
 * vendor rating
 * number of ratings
 * ships to / from

The two most important numeric predictors, product quantity and quality (# of grams, % purity), are embedded in the freeform title string. In order to access and transform these variables, I use regular expressions to parse the strings.

Here is an example of a real title string:
Parsing it with the quantity regex yields:
Parsing it with the quality regex yields: 

After each page dictionary is built, the function saves the data as a JSON file (e.g. `page12.json`). This is done so that information is not lost if the connection is interrupted during the collection process, which can take several minutes to hours.

## Cocaine Dataset

The cleaned dataset yielded approximately 1,500 product listings for cocaine. 

embed of Google Sheets with sample



add photo of market listing
add gif of Selenium crawling


Notes on transforms from Data cleaning
Link to data


### Interesting Findings

A few interesting findings:
* Cocaine costs around $90USD per gram. (median price per gram)
* Of all countries represented, the highest proportion of listings have their shipping origin in the Netherlands (NL).
* Prices go up substantially for anything shipped to or from Australia.


The Gradient Boosted tree demonstrated that 1-star ratings within the past 1 month were correlated with vendors selling at lower prices.

### Let's Try Math On It
In order to synthesize all of the numeric information I was now privy to, I turned to scikit-learn and its libraries of machine learning models. In particular, I wanted to evaluate how well models in the linear regression family and decision tree family of models fit my data.

##### Models evaluated were
* Linear Regression
* 

describe how I separated data into target (price) and set X predictors (list predictor variables)

Briefly describe model selection (Lin Reg and decision trees): what models were considered, how those models make predictions, and the scores they got on 

Show predictions of best model

conclude with limitations and future potential 
